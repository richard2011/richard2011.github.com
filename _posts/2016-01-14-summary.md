---
layout: post
title: 2015技术总结
categories: other
tags: other
---

{{ page.title }}
================

很高兴在卷皮网架构成长阶段加了基础架构部，我们致力于构建一个异步化服务治理平台。在卷皮1.0中，这是由PHP到JAVA服务化的推进，我们急需一个成熟稳定的SOA（RPC）框架，所以引入了阿里的Dubbo服务框架，把应用拆分进行服务化。为了更好地了解服务调用链路，我们参考了Google Dapper论文，实现分布式服务链路跟踪系统，不仅还原了Dubbo服务调用链路，还把mysql和redis的调用信息整合，这对于开发人员问题查找和性能调优都非常有帮助。在构建这系统时，我们后台系统采用了AngulaJS、Bootstrap和D3js进行一些数据可视化的尝试。   
 
Dubbo或者RPC的副作用是一旦某个RPC存在瓶颈时会导致整个调用链路就变慢，大促的时候更为突出。同时单一庞大的集中式关系型数据库限制问题也逐渐成为瓶颈，我们深知构建一个分布式的关系型数据库是一个很庞大的工程，行业也没有一个好的解决方案，我们也无意这样做。基于以上原因，我们开始构建下一代技术架构，并命名为轩辕，这是一个CQRS（命令查询职责分离）、 DDD（领域驱动设计）、EDA（事件驱动架构）的架构。这像是一次自我的革命，我们抛弃了很多传统的观念，开始去潜心研究CQRS和DDD的思想，并努力地实现与落地。  
 
一些问题随之而来，有些问题现在看来比较严重。如，程序需要差异化部署，其实很多分布式中间件都需要差异化部署，像Zookeeper、Kafka等，具体表现为都需要配置一个唯一的序号(一般由0开始，递增1)，这小小的配置在运维人员看来是不可容忍的，他们主要的观点是增加了人为操作，不仅增加工作量还容易出错，这迫使我们要把架构修成支持无差异部署。从中我们反思必须要有配置中心或者一个资源管理的工具，Mesos和YARN提供了类似功能也是可以参考的。内存计算的不可靠性，在DDD的概念中，领域对象常驻内存是基础，但是开发人员会觉得数据没有落地到关系型数据库就没有安全感，就会不断地质疑内存计算，而我们又没有提供一个可靠的方案打消他们的怀疑，Event Souring确实个令人头痛的问题，我们一直在试不同的方案，这情况迫使我们把领域对象放在redis中，又回到单一集中式存储和资源竟争的问题上了。中间件选型问题，原来架构非常依赖MQ，我们选用了阿里RocketMQ，没有经过统份的预研，简单地认为RocketMQ是类似Kafka追求高吞吐量MQ而且是用JAVA写的，后续发现RocketMQ一些BUG严重阻碍我们的主流程，而且发现的比较晚，最后我们决定把RocketMQ换成Kafka。从这几个问题中我们得到很大的教训，这套架构方案性能不是首要解决的问题，可靠性才急需要解决的问题。解决（更准确说是妥协）了以上这几个问题，轩辕1.0总算上线了。轩辕1.x,2.x将会不断地递进，也成为了我们2016年努力的方向。

Kafka的研究和维护，使我对分布式架构有更深层次的认识，每每重读他的设计文档和blog都很有收获，同时scala这种函数式语言会成为2016年学习的语言，试着去做一些用scala写小工具。我们私下都说希望轩辕在2016可以达到开源的标准，监控平台和服务治平台也是我们部分2016的重点项目，这两块也是值得去关注。
  
 

